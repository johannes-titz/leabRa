---
title: "LeabRa: Biologically realistic neural networks based on Leabra in R"
author: "Johannes Titz"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{LeabRa: Biologically realistic neural networks based on Leabra in R}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This package provides the Leabra artifical neural network algorithm for R. Leabra stands for "local error driven and associative biologically realistic algorithm". It is the Rolls Royce of artifical neural networks because it combines error driven learning and self organized learning in an elegant way, while focusing on a biologically plausible learning rule. If you have never heard of Leabra, you should read about it first. A good place to start is the computational cognitive neuroscience book (Part I): https://grey.colorado.edu/CompCogNeuro/index.php/CCNBook/Main (O'Reilly et al., 2016).

This version of Leabra is rather slow compared to the original implementation in C++. It was not intended for constructing large networks or running many trials; unless you do not care about processing resources. The main purpose of this implementation is to quickly try out new ideas; either in constructing new networks or in changing the algorithm to achieve certain outcomes. If you would want to do this with the C++ version, you would have to deal with optimized code, that is probably harder to read. Note that the Matlab version by Sergio Verduzuco-Flores (there is a short reference to it on this website: https://grey.colorado.edu/emergent/index.php/Leabra) has the same purpose and I recommend to try it out and read his great documentation. Actually his version was the template for this package and many things are written identically. Unfortunately, Matlab is non-free (in the libre sense), so I believe that this R version is the easiest way to get familiar with Leabra quickly. This is especially true for psychologists, who are usually acquainted with R anway and might want to "wrangle" with the data in their programming mother tongue.

What follows is a brief introduction for constructing networks with this package. The first network will be a pattern associator; it associates a specific input with a specific output in an error-driven fashion through a hidden layer. The second network will be a self-organized network that tries to categorize animals represented by feature vectors.

## Pattern Associator
You might say, that associating two patterns is unspectacular, because this can be achieved easily by back-propagating errors (Rumelhart et al., 1986). But Leabra uses a much more sophisticated learning rule, which is biologically oriented. In essence, you first present the input without the correct output. After that, you present the input *and* the correct output. Now, the weights are changed in such a way that the next time you present the input, the activation in the output will be more similar to the correct output. Changing weights is done completely *locally*; only the activations of the neurons over different time frames (short, medium and long term) are used to achieve this. Pretty impressive, right?

I think of it as if I wanted to learn a new foreign language vocabulary or geography. For instance, I want to associate the country Burkina Faso with its capital Ouagadougou (spelled [waga'du:gu]). In the first phase only Burkina Faso is presented and the neuronal network in my brain will try to produce the correct output Ouagadougou. It will likely not succeed in the beginning, maybe something similar will be output, but not the correct city. After this phase Burkina Faso and Ouagadougou are presented at the same time. Now, the spreading of activation will be correct. After these two phases the weights are changed, such that the next time I see Burkina Faso the output will be more similar to Ouagadougou. This adjustment happens by just looking at how active the units were over short, medium and long time frames.

### Constructing the Network
Let us load the package
```{r, message = F}
library(leabRa)
```

To reproduce the example we can use a seed. You can try to guess whose birthday is on July 22nd, 1904.
```{r}
set.seed(07221904)
```

To construct a network, we will at least need the dimensions of the network and the connections between the layers. We will specify three layers: input -- hidden -- output. They are quite small, so that the calculations do not take too long.

```{r}
dim_lays <- list(c(2, 5), c(2, 10), c(2, 5))
```

Let us now specify the connections between these layers. Layer 1 (input) should be connected with layer 2 (hidden). Layer 3 (output) will be bidirectionally connected with layer 2. If layer j sends projections to layer i, then 
connections[i, j] = strength > 0 and 0 otherwise. Strength specifies the relative strength of that connection with respect to the other projections to layer i. More intuitvely, just look at the rows and you will see that row (layer) 2 receives from columns (layers) 1 and 3; the connection with layer 1 is 5 times stronger ($0.2 \cdot 5 = 1$) than the connection with layer 3. Furthermore, row (layer) 3 receives from column (layer) 2.

```{r}
connections <- matrix(c(0, 0, 0,
                        1, 0, 0.2,
                        0, 1, 0), nrow = 3, byrow = T)
```

Note that in the current version of the package layers are either fully connected or unconnected. If you need partially connected layers, you will need to add this functionality on your own.

Now, we will create a network with default parameters.

```{r}
net <- network$new(dim_lays, connections)
```

The package is an R6 package, a special type of object oriented programming that behaves differently to the usual R object oriented programming style. You can see this, because we call the method of a class with the dollar sign (network**$**new(...)) instead of using a generic function. Furthermore, variables are also accessed via the dollar sign instead of the at-sign @.

*dim_lays* and *connections* is the minimum you need to specify a network, but if constructing other networks you should pay careful attention to *g_i_gain*, which controls overall inhibition in a layer (inhibitory condutance gain). If this value is not set carefully, you might not get what you want (too much or not enough activation).

### Creating Input Patterns
Now, we have a network, but no inputs. Let us create 15 random patterns with the method *create_inputs* in the network class. We want random patterns in layer 1 and 3, that are supposed to be associated during learning. We call these inputs inputs_plus, because this is what is presented to the network during the plus phase (correct output in layer 3 is presented). *prop_active* is the amount of active units in the patterns, activation is either 0.05 or 0.95. We choose .3, meaning that on average 30% of units will have an activation 0.95 and 70% an activation of 0.05.

```{r}
inputs_plus <- net$create_inputs(which_layers = c(1, 3),
                                 n_inputs = 15,
                                 prop_active = .3)
```

You could also create inputs with your own functions. The network will accept an external input list that has the length of the number of layers. Every element in the list should have the actviation values of the neurons for the specific layer.

For error-driven learning in Leabra fashion, we will need to remove the inputs of the output layer (layer 3) for the minus phase. We will call this list inputs_minus (the correct output is missing, it was subtracted). Functionals are neat, so we will use lapply here:

```{r}
inputs_minus <- lapply(inputs_plus, function(x) {x[3] <- list(NULL); return(x)})
```

### Learning
Now we can start learning with default parameters. The return value of the learning function is the output activation after each trial. In the next step we will use this output to calculate the error. During learning, the progress is reported by dots that represent a single trial. This means that minus, plus phase and weight changing has been performed for one stimulus. Every row is a new epoch. Epoch is a term in Leabra to describe that all stimuli were presented once.

```{r}
n_epochs <- 10
outs <- lapply(seq(n_epochs), function(x) net$learn_error_driven(inputs_minus,
                                                                 inputs_plus,
                                                                 lrate = 0.5))
```

### Plotting Results
The network class can calculate the mean absolute deviation (MAD) for each epoch. You can also use your own functions on these lists to calculate other types of errors like the cosine error. We will need the error for layer 3 (output).

```{r}
mad <- net$mad_per_epoch(outs, inputs_plus, 3)
```

How about a nice minimalistic plot to see if it worked?

```{r, fig.height=4, fig.show='hold', fig.width=6}
plot(mad, axes = F, pch = 16, family = "serif", type = "b",
     xlab = "epoch [#]",
     ylab = "mean absolute deviation [activation]",
     ylim = c(min(mad), max(mad)))
axis(1, at = seq(length(mad)), tick = T, family = "serif")
axis(2, at = seq(0, 1, 0.05), labels = seq(0, 1, 0.05), tick = T,
     family = "serif", las = 2)
```

The error gets smaller with each epoch, so the pattern associator seems to work just fine.

### Some Additional Notes
You can influence how many cycles should be run during the minus and plus phase, which are parameters for the *learn_error_driven* method. Besides, you could also implement your own functions to learn. Internally the *learn_error_driven* method is straightforward. It just use the method *cycle* to clamp the external input activations and to get the internal inputs from other layers. This is done several times for the minus phase (e.g. 50 times by default) and then for the plus phase (e.g. 25 times by default). After that the method *chg_wt* is called to adjust the weights. This procedure is repeated for every stimulus.

If you want to modify the initial weight matrix you have some options. When creating the network you can specify a function to create a random weight. The default function is:

```{r}
w_init_fun = function(x) 0.3 + 0.4 * runif(x)
```

It produces weights between 0.3 and 0.7 from a uniform distribution. Let us say, you want to generate weights from a normal distribution with a mean of 0.6 and a standard deviation of 0.1. You could specify the *w_init_fun* accordingly when constructing a new network object:

```{r}
net <- network$new(dim_lays, connections, w_init_fun = function(x) rnorm(x, mean = 0.6, sd = 0.1))
```

This might not be enough flexibility, so you can also create your own weight_matrix from scratch and just pass it as the parameter *w_init*, the initial weight matrix. *w_init* is a matrix of matrices (like a cell array in matlab), so pay attention when you create it from scratch.

This package uses R6 classes, meaning that you do not have to assign objects in the usual R way. For instance calling net$learn_error_driven above, actually modified the net object, although we did not make any explicit assignment. This is unusual for R and has some disadvantages, but it is faster and uses less resources (ideal for a simulation) than the more common S3/S4 classes. Just pay attention when you call methods in this package. They will modify objects in place.

## Hello World in "Connectionism": Categorizing Animals
Every time I get familiar with a neural network software, I try to create some typical examples. Certainly, one is the pattern associator. For me, another one is the example by Knight (1990) for unsupervised (self-organized) learning of animals. This is kind of my "hello world" for artifical neural networks.

Again, let us set a seed, so you can reproduce the example.

```{r}
set.seed(22071904)
```

We will start with the input patterns, because the network architecture depends on the dimension of these patterns.

### Input Patterns
The inputs for the network are animals represented by features that are either present or absent (Knight, 1990, p. 71). This data comes directly with the leabRa package and is called *animals*:

```{r}
animals
```

Because the network class (at the moment) only accepts a list as external inputs, we transform the data frame rows to elements of a list.

```{r}
inputs <- plyr::alply(animals, 1)
```

Furthermore we will need an empty list element (NULL) for the second layer.

```{r}
inputs <- lapply(inputs, function(x) list(x, NULL))
```

This is what I meant, when I wrote that R people might prefer wrangling with the data in their mother tongue.

### Network Architecture
We will use a 2-layer network, where layer 2 receives from layer 1. The size of layer 1 must be 6, because there are 6 features for representing an animal. The size of layer 2 is 3, meaning that the inputs will be categorized into three groups. You can experiment with the number of units in layer 2 to get other categories.

```{r}
dim_lays <- list(c(6, 1), c(3, 1))
connections <- matrix(c(0, 0,
                        1, 0), nrow = 2, byrow = T)
```

### Learning
We want to run the simulation not just once, but several times. To achieve this we can write a short function that initializes the network and then learns self-organized. The network will be different every time, because the weights are initialized randomly. You can think of this procedure as if you would let 100 participants observe ten different animals. The difference in participants is mimicked in the different weight matrices for every network.

```{r}
run_sim <- function(dim_lays, connections, inputs){
  net <- network$new(dim_lays, connections)
  net$learn_self_organized(inputs)
}
```

Now we can run the simulation. 100 runs seems reasonable, because the network is tiny. In the vignette the messages for the next code chunk were turned off to not clutter this document with the progress message.

```{r, message=FALSE}
n_runs <- 20
outs <- lapply(seq(n_runs), function(x) run_sim(dim_lays, connections, inputs))
```

### Plotting Results
The output is the activations of each layer after every stimulus presentation. We are actually only interested in layer 2, so let us extract these activations and transform them to data frames (some "wrangling" again).

```{r}
outs_layer_two <- lapply(outs, function(x) lapply(x, function(y) y[[2]]))
outs_layer_two <- lapply(outs_layer_two, function(x) do.call(rbind, x))
outs_layer_two <- lapply(outs_layer_two, round, 2)
```

Certainly, there are many ways to work with these activations. The first step will likely be to look at the distance matrices for every simulation run:

```{r}
dists <- lapply(outs_layer_two, proxy::simil)
round(dists[[1]], 2)
```

This is 1 distance matrix, but we have 100 of them; this is just too much information. We can average these values over the simulation runs by using a cool functional again:

```{r}
mean_dists <- Reduce("+", dists) / length(dists)
```

Now, we need to add the column and row names from the original data set, so that we know which animal is in which row.
```{r}
mean_dists_mtrx <- as.matrix(mean_dists)
colnames(mean_dists_mtrx) <- rownames(animals)
rownames(mean_dists_mtrx) <- rownames(animals)
```

We could run a cluster analysis and then look at a dendrogramm to see the categories. A heatmap of the distance matrix is also an option. Here, I will just use a graph to plot the results. We will need to use 1 - dist, because qgraph takes similarity as the parameter and not the disimilarity (distance).

```{r, fig.height=5, fig.width=5}
library(qgraph)
qgraph(1 - mean_dists_mtrx, layout = "spring", vsize = 6)
```

There seem to emerge three categories. One is dominated by the similarity between dog and cat (they have the same feature vectors), but bats and whales also belong there: the mammals. Then we have robin, canary and to a lesser degree ostrich: the birds. Finally, snake and lizzard, and the alligator ("all", as of the abbreviation algorithm in qgraph): reptiles. Whale, bat and ostrich are rather unusual for their category, so they are bit further away from the other members. Obviously, the example by Knight is somewhat artifical, but in this sense it also my favorite "hello world" example for *artifical* neural networks.

### Some Additional Notes
I received a criticism that the network actually only represents the inputs in a slightly different way. There is still a lot of variation possible, because I analyze all 3 output units with the simil function and they can have values between 0 and 1. We can just plot the the graph on the inputs without learning to understand this criticism.

```{r}
dists2 <- proxy::simil(animals)
qgraph(dists2,
       layout = "spring",
       vsize = 6)
```

You can already see that this still look somewhat different to the above version. But let us do it more thouroughly. We will take a binary approach, the network has to decide for one specific category with the help of two functions.

```{r}
set_won <- function(matrix){
  t(apply(matrix, 1, function(x) {x[-which.max(x)] <- 0; x}))
}

set_won2 <- function(matrix){
  t(apply(matrix, 1, function(x) {x[which.max(x)] <- 1; x}))
}

outs_layer_two <- lapply(outs, function(x) lapply(x, function(y) y[[2]]))
outs_layer_two <- lapply(outs_layer_two, function(x) do.call(rbind, x))
outs_layer_two <- lapply(outs_layer_two, set_won)
outs_layer_two <- lapply(outs_layer_two, set_won2)

``` 
The rest stays the same:

```{r}
dists <- lapply(outs_layer_two, proxy::simil)
round(dists[[1]], 2)

mean_dists <- Reduce("+", dists) / length(dists)

mean_dists_mtrx <- as.matrix(mean_dists)
colnames(mean_dists_mtrx) <- rownames(animals)
rownames(mean_dists_mtrx) <- rownames(animals)

qgraph(mean_dists_mtrx, layout = "spring", vsize = 6)
```

## Summary and Restrictions
These examples show that leab*R*a seems to work fine for two typical use cases. Still, I cannot guarantee that the code is correct in every detail. Furthermore, there are some differences to the original C++ code. For instance, you cannot specify partial connections. Besides, the nxx1-function is a step-function to reduce calculation resources. Overall, the algorithm should still produce very similar results to the original Leabra implementation.

## References
Knight, K. (1990). Connectionist ideas and algorithms. *Communications of the ACM*, *33*(11), 59–74.

O'Reilly, R. C., Munakata, Y., Frank, M. J., Hazy, T. E., and Contributors (2016). *Computational Cognitive Neuroscience*. Wiki Book, 3rd (partial) Edition. URL: http://ccnbook.colorado.edu

Rumelhart, D E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating errors. *Nature*. *323*(6088): 533–536. doi:10.1038/323533a0.
